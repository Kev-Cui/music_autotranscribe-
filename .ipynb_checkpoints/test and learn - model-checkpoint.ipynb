{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fe4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import pickle\n",
    "\n",
    "with open(\"piano_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    print('X:',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0342c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['start_time', 'end_time', 'pitch', 'velocity', 'mfccs'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e52725",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []\n",
    "for song in data:\n",
    "    filtered_song = []\n",
    "    for note in song:\n",
    "        if (note['mfccs'][0].sum()!=0) and (note['mfccs'].shape[1] <= 50):\n",
    "            filtered_song.append(note)\n",
    "    filtered_data.append(filtered_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8e6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make X (MFCCs) and y (note lables):\n",
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "for song in filtered_data:\n",
    "    for note in song:\n",
    "        X.append(note['mfccs'])\n",
    "\n",
    "y = []\n",
    "for song in filtered_data:\n",
    "    for note in song:\n",
    "        note_servo = [note['pitch'], note['velocity']]\n",
    "        y.append(np.array(note_servo))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde7199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_len_store = []\n",
    "for note in X:\n",
    "    note_len_store.append(len(note[0]))\n",
    "max_note_length = max(note_len_store)\n",
    "max_note_length\n",
    "\n",
    "for i, note in enumerate(X):\n",
    "    X[i] = np.pad(note, ((0, 0), (0, max_note_length - note.shape[1])), mode='constant')\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e7d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for i, note in enumerate(X):\n",
    "    X[i] = scaler.fit_transform(note) # transform the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d718f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139db0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 11, 32)            4832      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 5, 32)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 3, 64)             6208      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1, 64)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27746 (108.38 KB)\n",
      "Trainable params: 27746 (108.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(layers.Input(shape=(13, 50)))  # 1754 time steps for each MFCC\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))  # Optional dropout for regularization\n",
    "model.add(layers.Dense(units=64, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "# Assuming you want to predict MIDI note information (pitch, velocity)\n",
    "output_dim = 2  # Adjust based on your output dimensions\n",
    "model.add(layers.Dense(units=output_dim, activation='linear'))  # Linear activation for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Use appropriate loss function\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f57220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "8414/8414 [==============================] - 30s 3ms/step - loss: 171.8621 - val_loss: 994.3377\n",
      "Epoch 2/5\n",
      "8414/8414 [==============================] - 29s 3ms/step - loss: 132.1726 - val_loss: 903.5503\n",
      "Epoch 3/5\n",
      "8414/8414 [==============================] - 29s 3ms/step - loss: 127.4046 - val_loss: 743.9528\n",
      "Epoch 4/5\n",
      "8414/8414 [==============================] - 27s 3ms/step - loss: 124.8515 - val_loss: 618.1443\n",
      "Epoch 5/5\n",
      "8414/8414 [==============================] - 28s 3ms/step - loss: 123.0028 - val_loss: 523.1492\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, \n",
    "                    epochs=5, batch_size=64,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784c08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
